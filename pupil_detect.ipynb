{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa39163",
   "metadata": {},
   "source": [
    "**Detecting the Card and Calculating its width**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ef2c1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The width of card is 531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def clahe(img, clip_limit=2.0, grid_size=(8,8)):\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)\n",
    "    return clahe.apply(img)\n",
    "\n",
    "src = cv2.imread(\"C://Users//tanus//OneDrive//Desktop//CREATIVITY//Cynaptics and ML//Jain_software//SLA task 1//In//img6.jpeg\")\n",
    "\n",
    "# HSV thresholding to get rid of as much background as possible\n",
    "hsv = cv2.cvtColor(src.copy(), cv2.COLOR_BGR2HSV)\n",
    "lower_blue = np.array([0, 0, 120])\n",
    "upper_blue = np.array([180, 38, 255])\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "result = cv2.bitwise_and(src, src, mask=mask)\n",
    "b, g, r = cv2.split(result)\n",
    "g = clahe(g, 5, (3, 3))\n",
    "\n",
    "# Adaptive Thresholding to isolate the card\n",
    "img_blur = cv2.blur(g, (9, 9))\n",
    "img_th = cv2.adaptiveThreshold(img_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                               cv2.THRESH_BINARY, 51, 2)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(img_th,\n",
    "                                           cv2.RETR_CCOMP,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter the rectangle by choosing only the big ones\n",
    "# and choose the brightest rectangle as the card\n",
    "max_brightness = 0\n",
    "canvas = src.copy()\n",
    "for cnt in contours:\n",
    "    rect = cv2.boundingRect(cnt)\n",
    "    x, y, w, h = rect\n",
    "    if w*h > 40000 and w*h<200000:\n",
    "        mask = np.zeros(src.shape, np.uint8)\n",
    "        mask[y:y+h, x:x+w] = src[y:y+h, x:x+w]\n",
    "        brightness = np.sum(mask)\n",
    "        if brightness > max_brightness:\n",
    "            brightest_rectangle = rect\n",
    "            max_brightness = brightness\n",
    "        # cv2.imshow(\"mask\", mask)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "x, y, w, h = brightest_rectangle\n",
    "print(\"The width of card is\", w)\n",
    "cv2.rectangle(canvas, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
    "# cv2.imshow(\"canvas\", canvas)\n",
    "# cv2.imwrite(\"card_detected.jpg\", canvas)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee85920",
   "metadata": {},
   "source": [
    "The width of the card on forehead is 531 in terms of pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b0297",
   "metadata": {},
   "source": [
    "**Detecting Pupils using dlib library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afbc61c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dlib in c:\\users\\tanus\\anaconda3\\lib\\site-packages (19.24.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002f8e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\tanus\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c6af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import io\n",
    "import argparse\n",
    "import dlib\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33fc0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelReader(img,startHorizontal,startVertical,height):\n",
    "\t'''\n",
    "\tUsed to read specific pixel of given image.\n",
    "\timg = image \n",
    "\tstartHorizontal =  horizontal starting pixel value\n",
    "\tstartVertical = vertical starting value\n",
    "\theight = maximum limit for pixel reading\n",
    "\t'''\n",
    "\t# list for satisfied pixels\n",
    "\tblackColour = []\n",
    "\n",
    "\t# for loops for traversing pixels\n",
    "\tfor j in range(-int(height*1.5), 0):\n",
    "\t\tfor i in range(startVertical- height,startVertical+int(height*1.5)):\n",
    "\t\t\t# setting lower bound for pixels, termination \n",
    "\t\t\tblackLowerRange = [80, 50, 50]\n",
    "\t\t\tpixel = startHorizontal + j\n",
    "\t\t\tcolorCI = img[int(pixel), i]\n",
    "\t\t\tif ((colorCI[0] <= blackLowerRange[0] and colorCI[1] <= blackLowerRange[1] and colorCI[2] <= blackLowerRange[2])):\n",
    "\t\t\t\tblackColour.append([int(pixel), i])\n",
    "\treturn blackColour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0864ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceAttributeVector(image):\n",
    "\t'''\n",
    "\tUsed to get the 68 facial attributes of face image.\n",
    "\timage: it is an image.\n",
    "\t'''\n",
    "\t# dlib shape predictor \n",
    "\tpredictorPath = \"C://Users//tanus//OneDrive//Desktop//CREATIVITY//Cynaptics and ML//Jain_software//SLA task 1//shape_predictor_68_face_landmarks.dat\"\n",
    "\tdetector = dlib.get_frontal_face_detector()\n",
    "\tpredictor = dlib.shape_predictor(predictorPath)\n",
    "\tdets = detector(image)\n",
    "\n",
    "\t# if dlib is able to detect the faces \n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\tfor k, d in enumerate(dets):\n",
    "\t\tshape = predictor(image, d)\n",
    "\n",
    "\t# to get the 68 facial points detect from dlib into a list\n",
    "\tfaceCoord = np.empty([68, 2], dtype = int)\n",
    "\n",
    "\tfor b in range(68):\n",
    "\t\tfaceCoord[b][0] = shape.part(b).x\n",
    "\t\tfaceCoord[b][1] = shape.part(b).y\n",
    "\n",
    "\treturn faceCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd009c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEyeCoordinates(image, faceCoord):\n",
    "\t'''\n",
    "\tUsed to crop the eyes from image\n",
    "\timage: it is an image.\n",
    "\tfaceCoord: array of facial landmarks coordinates\n",
    "\t'''\n",
    "\t# using facial points to crop the part of the eyes from image\n",
    "\tleftEye = image[int(faceCoord[19][1]):int(faceCoord[42][1]),int(faceCoord[36][0]):int(faceCoord[39][0])]\n",
    "\trightEye = image[int(faceCoord[19][1]):int(faceCoord[42][1]),int(faceCoord[42][0]):int(faceCoord[45][0])]\n",
    "\n",
    "\teyeLCoordinate = [int(faceCoord[37][0]+int((faceCoord[38][0]-faceCoord[37][0])/2)), int(faceCoord[38][1]+int((faceCoord[40][1]-faceCoord[38][1])/2))]\n",
    "\teyeRCoordinate = [int(faceCoord[43][0]+int((faceCoord[44][0]-faceCoord[43][0])/2)), int(faceCoord[43][1]+int((faceCoord[47][1]-faceCoord[43][1])/2))]\n",
    "\n",
    "\tleftBlackPixel = pixelReader(image,eyeLCoordinate[1],eyeLCoordinate[0],int((faceCoord[38][0]-faceCoord[37][0])/2))\n",
    "\trightBlackPixel = pixelReader(image, eyeRCoordinate[1], eyeRCoordinate[0], int((faceCoord[44][0]-faceCoord[43][0])/2))\n",
    "\treturn leftEye, rightEye, leftBlackPixel, rightBlackPixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "051b4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPupilPoint(img, blackCoordinates, eyeTopPointX, eyeBottomPointY):\n",
    "\t'''\n",
    "\tUsed to get the coordinates of the pupil \n",
    "\timage: cropped eye image\n",
    "\tblackCoordinates: It is the array of the black color pixels inside the eyes\n",
    "\teyeTopPointX: eye's starting coordinates horizontally\n",
    "\teyeBottomPointY: eye's starting coordinates vertically\n",
    "\t'''\n",
    "\t# after getting the eyes pixels applying cv2 method to detect circle pixels which we can do using houghcircles \n",
    "\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\tcircles = cv2.HoughCircles(gray,cv2.HOUGH_GRADIENT, dp = 1,minDist = 5,\n",
    "\t\tparam1=250,param2=10,minRadius=1,maxRadius=-1)\n",
    "\t\n",
    "\t# check if houghcircles has detect any circle or not\n",
    "\tif circles is not None:\n",
    "\t\tcircles = np.uint16(np.around(circles))\n",
    "\t\tfor i in circles[0,:1]:\n",
    "\t\t\tpupilPoint = [int(eyeTopPointX[0])+ i[0],int(eyeBottomPointY[1]) + i[1]]\n",
    "\telse:\n",
    "\t\t# if HoughCircles is unable to detect the circle than using eyes points to get pupil points \n",
    "\t\ta = 0\n",
    "\t\tfor j,k in blackCoordinates:\n",
    "\t\t\tif a == int(len(blackCoordinates)/2):\n",
    "\t\t\t\tpupilPoint = [k,j]\n",
    "\t\t\ta += 1\n",
    "\treturn pupilPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46db37",
   "metadata": {},
   "source": [
    "**Detecting the pupil coordinates and saving the image to output folder while drawing a line between the pupils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f28243f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[331, 546] [632, 548]\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "r=[]\n",
    "for imageName in os.listdir(\"C://Users//tanus//OneDrive//Desktop//CREATIVITY//Cynaptics and ML//Jain_software//SLA task 1//In//\"):\n",
    "\timage = io.imread(\"C://Users//tanus//OneDrive//Desktop//CREATIVITY//Cynaptics and ML//Jain_software//SLA task 1//In//\"+imageName)\n",
    "\timage = imutils.resize(image, width=1000)\n",
    "\t# getting the faceattribute vector from dlib\n",
    "\tfaceVector = getFaceAttributeVector(image)\n",
    "\n",
    "\t# getting the eye points\n",
    "\tleftEye, rightEye, eyeLeftBlackPixels, eyeRightBlackPixels = getEyeCoordinates(image, faceVector)\n",
    "\n",
    "\t# getting pupilpoint for left eye\n",
    "\t# leftEye is the cropped part of face image\n",
    "\tleftEyeCoord, eyeBrowCoord = faceVector[36], faceVector[19]\n",
    "\tleftPupilPoint = getPupilPoint(leftEye, eyeLeftBlackPixels, leftEyeCoord, eyeBrowCoord); l=leftPupilPoint\n",
    "\n",
    "\t# getting pupilpoint for right eye\n",
    "\t# rightEye is the cropped part of face image\n",
    "\trightEyeCoord = faceVector[42]\n",
    "\trightPupilPoint = getPupilPoint(rightEye, eyeRightBlackPixels, rightEyeCoord, eyeBrowCoord); r=rightPupilPoint\n",
    "\t\n",
    "\t# drawing pupil points on image\n",
    "\tcv2.circle(image, tuple(leftPupilPoint), 5, (255, 0, 0), -1)\n",
    "\tcv2.circle(image, tuple(rightPupilPoint), 5, (255, 0, 0), -1)\n",
    "\tfinalImage = cv2.cvtColor(image, cv2.COLOR_RGB2BGR); finalImage=cv2.line(finalImage, tuple(l), tuple(r), (0, 255, 0), thickness=5)\n",
    "\tcv2.imwrite(\"C://Users//tanus//OneDrive//Desktop//CREATIVITY//Cynaptics and ML//Jain_software//SLA task 1//Out//\"+imageName,finalImage)\n",
    "print(l, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e4b05",
   "metadata": {},
   "source": [
    "**Calculating the pupil distance using the pinhole camera assumption and known card dimension (8.56 cm width) and displaying it on line in centimeter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76451825",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARALLEL_PLANE_SCALING_FACTOR=1.372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feeda33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pupil distance in cm is 6.999679935227999\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def scaleit(l,r,w):\n",
    "    pupil_dist_in_pixel=float(math.sqrt((l[0]-r[0])*(l[0]-r[0])+(l[1]-r[1])*(l[1]-r[1])))\n",
    "    return float((pupil_dist_in_pixel*9)/w)*PARALLEL_PLANE_SCALING_FACTOR\n",
    "print(\"The pupil distance in cm is\", scaleit(l,r,w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccf12d1",
   "metadata": {},
   "source": [
    "**Writing the PD calculated on the line between pupils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0aac72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=[]\n",
    "k.append(int((l[0]+r[0])/2))\n",
    "k.append(int((l[1]+r[1])/2))\n",
    "img = cv2.imread(\"C://Users//tanus//OneDrive//Desktop//CREATIVITY//Cynaptics and ML//Jain_software//SLA task 1//Out//img6.jpeg\")\n",
    "img = cv2.putText(img, str(math.ceil(scaleit(l,r,w)))+\"cm\", tuple(k), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5, cv2.LINE_AA)\n",
    "cv2.imwrite(\"C://Users//tanus//OneDrive//Desktop//CREATIVITY//Cynaptics and ML//Jain_software//SLA task 1//\"+\"result.jpg\",img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
